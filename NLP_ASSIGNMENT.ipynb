{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN0HRl+hO1qFcLDU5IwrHW4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahendrasiingh/NLP-ASSIGNMENT/blob/main/NLP_ASSIGNMENT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Install required libraries\n",
        "!pip install nltk gensim\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Qa_ecP5fjWL",
        "outputId": "a2dd3965-fb15-4a5f-b5d1-fe5a0d8722c2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.11/dist-packages (4.3.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Import libraries\n",
        "import nltk\n",
        "import gensim\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n"
      ],
      "metadata": {
        "id": "oZtj320cfmBz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Download NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXEEA9-jfnw8",
        "outputId": "7d883922-ef9e-47ef-b694-25ce68b52416"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_data = [\n",
        "    \"I love natural language processing and machine learning!\",\n",
        "    \"Word embeddings are really helpful for many NLP tasks.\",\n",
        "    \"Preprocessing is an important step in text analysis.\"\n",
        "]\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_text(text):\n",
        "    return word_tokenize(text.lower())\n"
      ],
      "metadata": {
        "id": "narywhHZfx3q"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Lemmatization function\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "def lemmatize_tokens(tokens):\n",
        "    return [lemmatizer.lemmatize(token) for token in tokens]\n"
      ],
      "metadata": {
        "id": "CHkheZTyf5Cl"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stop words removal function\n",
        "stop_words = set(stopwords.words('english'))\n",
        "def remove_stop_words(tokens):\n",
        "    return [token for token in tokens if token not in stop_words and token.isalpha()]\n"
      ],
      "metadata": {
        "id": "bdisT4spf7Oh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mENwwgp7gMyr",
        "outputId": "cfc3d5b2-f5a1-4a1e-834d-a913bd788797"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final preprocessing pipeline\n",
        "preprocessed_text = []\n",
        "for sentence in text_data:\n",
        "    tokens = tokenize_text(sentence)\n",
        "    tokens = lemmatize_tokens(tokens)\n",
        "    tokens = remove_stop_words(tokens)\n",
        "    preprocessed_text.append(tokens)\n",
        "\n",
        "print(\"Preprocessed Text:\")\n",
        "print(preprocessed_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Y1OJyzEgFWR",
        "outputId": "1d76806f-cc19-425f-ee64-300a2468a127"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preprocessed Text:\n",
            "[['love', 'natural', 'language', 'processing', 'machine', 'learning'], ['word', 'embeddings', 'really', 'helpful', 'many', 'nlp', 'task'], ['preprocessing', 'important', 'step', 'text', 'analysis']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Word2Vec model\n",
        "model = Word2Vec(sentences=preprocessed_text, vector_size=100, window=5, min_count=1, workers=4)\n"
      ],
      "metadata": {
        "id": "xsx-0_w_gQUO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: check embedding for a word\n",
        "word = 'nlp'\n",
        "if word in model.wv:\n",
        "    print(f\"Word2Vec embedding for '{word}':\")\n",
        "    print(model.wv[word])\n",
        "else:\n",
        "    print(f\"'{word}' not in vocabulary.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYbw19vNgSGv",
        "outputId": "f7b833f3-159a-45f6-94d2-5935429304af"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec embedding for 'nlp':\n",
            "[-1.9442164e-03 -5.2675214e-03  9.4471136e-03 -9.2987325e-03\n",
            "  4.5039477e-03  5.4041781e-03 -1.4092624e-03  9.0070926e-03\n",
            "  9.8853596e-03 -5.4750429e-03 -6.0210000e-03 -6.7469729e-03\n",
            " -7.8948820e-03 -3.0479168e-03 -5.5940272e-03 -8.3446801e-03\n",
            "  7.8290224e-04  2.9946566e-03  6.4147436e-03 -2.6289499e-03\n",
            " -4.4534765e-03  1.2495709e-03  3.9146186e-04  8.1169987e-03\n",
            "  1.8280029e-04  7.2315861e-03 -8.2645155e-03  8.4335366e-03\n",
            " -1.8889094e-03  8.7011540e-03 -7.6168370e-03  1.7963862e-03\n",
            "  1.0564864e-03  4.6005251e-05 -5.1032533e-03 -9.2476979e-03\n",
            " -7.2642174e-03 -7.9511739e-03  1.9137275e-03  4.7846674e-04\n",
            " -1.8131376e-03  7.1201660e-03 -2.4756920e-03 -1.3473093e-03\n",
            " -8.9005642e-03 -9.9254129e-03  8.9493981e-03 -5.7539381e-03\n",
            " -6.3729975e-03  5.1994072e-03  6.6699935e-03 -6.8316413e-03\n",
            "  9.5975993e-04 -6.0084737e-03  1.6473436e-03 -4.2892788e-03\n",
            " -3.4407973e-03  2.1856665e-03  8.6615775e-03  6.7281104e-03\n",
            " -9.6770572e-03 -5.6221043e-03  7.8803329e-03  1.9893574e-03\n",
            " -4.2560520e-03  5.9881213e-04  9.5209610e-03 -1.1027169e-03\n",
            " -9.4246380e-03  1.6084099e-03  6.2323548e-03  6.2823701e-03\n",
            "  4.0916502e-03 -5.6502391e-03 -3.7069322e-04 -5.5317880e-05\n",
            "  4.5717955e-03 -8.0415895e-03 -8.0183093e-03  2.6475071e-04\n",
            " -8.6082993e-03  5.8201565e-03 -4.1781188e-04  9.9711772e-03\n",
            " -5.3439774e-03 -4.8613906e-04  7.7567734e-03 -4.0679323e-03\n",
            " -5.0159004e-03  1.5900708e-03  2.6506938e-03 -2.5649595e-03\n",
            "  6.4475285e-03 -7.6599526e-03  3.3935606e-03  4.8997044e-04\n",
            "  8.7321829e-03  5.9827138e-03  6.8153618e-03  7.8225443e-03]\n"
          ]
        }
      ]
    }
  ]
}